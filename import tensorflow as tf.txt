import tensorflow as tf
import numpy as np
from matplotlib import pyplot as plt
from matplotlib import image as mpimg
from tensorflow import keras
from tensorflow.keras import datasets, optimizers, Sequential
from PIL import Image
from scipy.interpolate import UnivariateSpline
from scipy.interpolate import interp1d
import scipy.io as scio


radius = tf.constant(80e-6, dtype = tf.complex64)
n = tf.constant(1., dtype=tf.complex64)
n_sub = tf.constant(1.53, dtype = tf.complex64)
lamb0 = tf.linspace(0.45e-6, 0.65e-6, 3)
# lamb0 = [0.42e-6, 0.532e-6, 0.633e-6]
lamb0 = tf.cast(lamb0, dtype = tf.complex64)
lamb = lamb0 / n      # 介质中的波长
ssratio = 3 # ss: super sampling

fmax = 2e-15    # upper bound of group delay
dl = tf.constant(0.28e-6, dtype=tf.complex64)   # pixel size
NA = tf.constant(0.3 , dtype = tf.complex64)     # N.A. of the metalens
gap = tf.constant(335e-6, dtype = tf.complex64)

N = int(abs(2*radius/dl))
NN = 681
f = radius/np.tan(np.arcsin(NA))    # focal length
wvlnum = len(lamb0)

pi = tf.convert_to_tensor(np.pi, dtype=tf.complex64)
c = tf.constant(2.99792458e8, dtype=tf.complex64)
w0 = 2*pi*(c/lamb0[0])

dlp = dl / ssratio
fxmp = 1 / dlp
fymp = 1 / dlp

batchsz = 3
batchratio = 120/batchsz
rpt = 5000

## 1D Initial value
InitialVal0 = np.load('AML-byint-v4.4-NA0.3-p0.28um-gap335um-r80um-2fs-DesignedInitial-meta0.npy')
InitialVal1 = np.load('AML-byint-v4.4-NA0.3-p0.28um-gap335um-r80um-2fs-DesignedInitial-meta1.npy')

gdtmp = (InitialVal0[1] + fmax/2) / fmax
InitialVal0[1] = -tf.math.log(1/(gdtmp) - 1)
gdtmp = (InitialVal1[1] + fmax/2) / fmax
InitialVal1[1] = -tf.math.log(1/(gdtmp) - 1)

phaseinit1 = tf.constant_initializer(InitialVal0[0])
gdinit1 = tf.constant_initializer(InitialVal0[1])
phaseinit2 = tf.constant_initializer(InitialVal1[0])
gdinit2 = tf.constant_initializer(InitialVal1[1])

def sd_lensphase(lad):      # generating a standard lens phase
    lad = tf.cast(lad, dtype = tf.complex64)
    x = tf.linspace(-radius, radius, N)
    x = tf.cast(x, dtype = tf.complex64)
    y = x
    xx,yy = tf.meshgrid(x,y)
    
    k = 2*pi/lad   
    phase = -k*(tf.math.sqrt((tf.math.square(xx)+tf.math.square(yy)+f*f))-f)    
    phase = tf.cast(tf.math.real(phase), dtype = tf.float32)
    phase = tf.math.mod(phase, 2*np.pi)
    phase = tf.cast(phase, dtype = tf.complex64)       
    return phase

def processor2(inp):     # arbitrary --> NN*ssratio without ssratio
    n1 = len(inp)
    a00 = tf.zeros([int(NN*ssratio / 2 - n1 / 2), n1], dtype=tf.complex64)
    a01 = a00
    a10 = tf.zeros([NN*ssratio, int(NN*ssratio / 2 - n1 / 2)], dtype=tf.complex64)    
    a11 = a10  
    arr = tf.concat([a00, inp, a01], axis=0)
    inp = tf.concat([a10, arr, a11], axis=1)    
    return inp

@tf.function()
def processor3(inp):     # arbitrary --> NN*ssratio with super sampling
    n1 = len(inp)
    a00 = tf.zeros([int(NN / 2 - n1 / 2), n1], dtype=tf.complex64)
    a01 = a00
    a10 = tf.zeros([NN, int(NN / 2 - n1 / 2)], dtype=tf.complex64)    
    a11 = a10  
    arr = tf.concat([a00, inp, a01], axis=0)
    inp = tf.concat([a10, arr, a11], axis=1)
    inp = tf.repeat(inp, ssratio, axis=0)
    inp = tf.repeat(inp, ssratio, axis=1)
    return inp

def DimensionTransMatrix(nn):
    # 计算维度变换的矩阵
    x2 = np.linspace(-int(nn/2), int(nn/2), nn)
    xx, yy = np.meshgrid(x2, x2)
    raa = np.sqrt(np.square(xx)+np.square(yy))
    raa[raa > int(nn/2)] = 0
    raa = nn/2-raa
    raa = np.reshape(raa,[nn*nn,1])
    TransMat = tf.one_hot(raa, nn)
    TransMat = np.reshape(TransMat,[nn*nn,nn])
    return TransMat
    
TransMatN = DimensionTransMatrix(N)

def OneD2TwoD(phase1d,transmat):
    # 将一维的相位转化为二维矩阵
    nlength = len(phase1d)
    phase1d = tf.reshape(phase1d,[nlength,1])
    phase2d = transmat @ phase1d
    phase2d = tf.reshape(phase2d,[nlength,nlength])
    return phase2d

def source(nn):      # generating the circle intensity
    x = np.linspace(-1, 1, nn)
    y = x
    xx, yy = np.meshgrid(x, y)
    raa = np.square(xx)+np.square(yy)
    Ein = np.ones([nn, nn])
    Ein[raa > 1] = 0
    Ein = tf.cast(Ein, dtype = tf.complex64)
    Ein = processor3(Ein)
    return Ein

Ein = source(N)
Ein = tf.reshape(Ein, [1, NN*ssratio, NN*ssratio])
Ein = tf.repeat(Ein, batchsz, axis = 0)

@tf.function()
def source2(ein, lad, inang):
    # Adding phase to the circular incident field
    ## 乘上倾斜相位
    kvector = 2*pi/lad
    xposition = tf.cast(range(0, NN*ssratio, 1), dtype = tf.complex64)   # 横向的位置坐标
    xposition = xposition*dlp
    phase_delay = tf.math.exp(1j*kvector*tf.math.sin(inang)*xposition)     # 不同x位置的相位延迟
    phase_delay = tf.reshape(phase_delay, [NN*ssratio, 1])
    phase_delay = tf.tile(phase_delay, [1, NN*ssratio])
    x_phase = ein*phase_delay
    ein = ein*x_phase   # 去掉强度为0的点的相位      
    return ein

@tf.function()
def source22(ein, lad, inang):
    # Adding phase to the circular incident field, considering batch size
    ## 乘上倾斜相位
    lad = tf.reshape(lad, [batchsz, 1])
    inang = tf.reshape(inang, [batchsz, 1])
    kvector = 2*pi/lad
    xposition = tf.cast(range(0, NN*ssratio, 1), dtype = tf.complex64)   # 横向的位置坐标
    xposition = xposition*dlp
    xposition = tf.reshape(xposition, [1,NN*ssratio])
    xposition = tf.repeat(xposition, batchsz, axis =0)
    phase_delay = tf.math.exp(1j*kvector*tf.math.sin(inang)*xposition)     # 不同x位置的相位延迟
    phase_delay = tf.reshape(phase_delay, [batchsz, NN*ssratio, 1])
    phase_delay = tf.tile(phase_delay, [1, 1, NN*ssratio])
    x_phase = ein*phase_delay
    ein = ein*x_phase   # 去掉强度为0的点的相位      
    return ein

@tf.function()
def prop(ein, dz, lad, nn):  # propagating calculation by angular spectrum method
    lad = lad / nn    
    kk = 2*pi / lad
    Np = NN * ssratio

    fxp = tf.linspace(-fxmp / 2, fxmp / 2, Np)
    fyp = tf.linspace(-fymp / 2, fymp / 2, Np)
    fxp = tf.cast(fxp, dtype=tf.complex64)  # 频率坐标
    fyp = tf.cast(fyp, dtype=tf.complex64)

    [fxp, fyp] = tf.meshgrid(fxp, fyp)

    fre_Ein = tf.signal.fftshift(tf.signal.fft2d(tf.signal.ifftshift(ein)))  # 要先验证下tf的傅里叶变换需要几次fftshift
    fre_Eout = fre_Ein * tf.exp(1j * kk * dz * tf.sqrt(1 - tf.square(fxp * lad) - tf.square(fyp * lad)))
    Eout = tf.signal.ifftshift(tf.signal.ifft2d(tf.signal.ifftshift(fre_Eout)))
    return Eout

@tf.function()
def prop2(inputlist, dz, nn):  # propagating calculation by angular spectrum method
    # Input size: list
    # Field size: [batchsz, NN*ssratio, NN*ssratio]
    lad0, ein = inputlist
    lad = lad0/nn
    kk = 2*pi / lad
    Np = NN * ssratio

    fxp = tf.linspace(-fxmp / 2, fxmp / 2, Np)
    fyp = tf.linspace(-fymp / 2, fymp / 2, Np)
    fxp = tf.cast(fxp, dtype=tf.complex64)  # 频率坐标
    fyp = tf.cast(fyp, dtype=tf.complex64)

    [fxp, fyp] = tf.meshgrid(fxp, fyp)
    fxp = tf.reshape(fxp, [1, NN*ssratio, NN*ssratio])
    fyp = tf.reshape(fyp, [1, NN*ssratio, NN*ssratio])

    fre_Ein = tf.signal.fftshift(tf.signal.fft2d(tf.signal.ifftshift(ein,[1,2])),[1,2])  # 要先验证下tf的傅里叶变换需要几次fftshift
    fre_Eout = fre_Ein * tf.exp(1j * kk * dz * tf.sqrt(1 - tf.square(fxp * lad) - tf.square(fyp * lad)))
    Eout = tf.signal.ifftshift(tf.signal.ifft2d(tf.signal.ifftshift(fre_Eout,[1,2])),[1,2])
    outputlist = [lad0, Eout]
    return outputlist

@tf.function()
def focuspoint(ein, lad, z = f, lensphase = None):     # generating focus point field
    if lensphase == None:
        lensphase = sd_lensphase(lad)
    lensphase = processor3(lensphase)
    lensphase = tf.math.exp(1j * lensphase)
    fp_t = prop(ein*lensphase, z, lad, n)
    return fp_t

@tf.function()
def preprocess(wvll, angg):
    # Generate the incident field and target image for the specific wavelength and incident angle
    # unit: m, rad
    ein = source2(Ein, wvll, angg)
    eintmp = source2(Ein, wvll, tf.constant(0, dtype = tf.complex64))    # The normal incident field
    eouttmp = focuspoint(eintmp, wvll) # The field at the focal plane with normal incident
    shift_d = (f)*tf.math.tan(angg)
    shift_p = int(tf.math.real(shift_d / dlp))
    a0 = tf.zeros([shift_p, NN*ssratio], dtype = tf.complex64)
    a1= eouttmp[0:NN*ssratio-shift_p, :]
    etar = tf.concat([a0, a1], axis = 0)
    wvll2 = wvll*tf.ones([NN*ssratio, NN*ssratio], dtype = tf.complex64)
    # angg2 = tf.reshape(angg, [1,1])
    # wvll2 = wvll
    # wvll2 = tf.reshape(wvll, [1])
    angg2 = angg
    einall = tf.stack([ein, wvll2], axis = 0)
    # einall = [ein, wvll2]
    return einall, etar, wvll2, angg2
    
# Loading the data
raw_dataset = tf.data.TFRecordDataset('metalens-fixedcondition.r80-NA0.3-cont-NN681-ssratio3-focusinair')
feature_description = {
    'condition': tf.io.FixedLenFeature([], tf.string, default_value=''),
    'incident': tf.io.FixedLenFeature([], tf.string, default_value=''),    
    'patt': tf.io.FixedLenFeature([], tf.string, default_value=''),
}

def _parse_function(example_proto):
  # Parse the input `tf.Example` proto using the dictionary above.
    return tf.io.parse_single_example(example_proto, feature_description)

parsed_dataset = raw_dataset.map(_parse_function).batch(batchsz).repeat(rpt)
dataset_iter = iter(parsed_dataset)

def focusprocess_2layer(ein, lad, slicestep, z, lensphase0, lensphase1):
    slicestep = tf.cast(slicestep, dtype = tf.complex64)
    lensphase0 = tf.cast(lensphase0, dtype = tf.complex64)
    lensphase1 = tf.cast(lensphase1, dtype = tf.complex64)
  
    lensphase0 = processor3(lensphase0)
    lensphase1 = processor3(lensphase1)
 
    lensphase0 = tf.math.exp(1j * lensphase0)
    lensphase1 = tf.math.exp(1j * lensphase1)
 
    outxz = []
    # layer1
    slicenum1 = int(gap/slicestep)
    for i in range(slicenum1):
        out = prop(ein*lensphase0, slicestep*i, lad, n_sub)
        outxz.append((out[:, int(NN*ssratio/2)]))
    
    # layer2
    out = prop(ein*lensphase0, gap, lad, n_sub)
    slicenum2 = int(z/slicestep)
    for i in range(slicenum2):      
        out2 = prop(out*lensphase1, slicestep*i, lad, n)
        outxz.append((out2[:, int(NN*ssratio/2)]))

    outxz = np.array(outxz)
    outxz = np.transpose(outxz)
    return outxz

def focusprocess_meta2only(ein, lad, slicestep, z, lensphase1):
    slicestep = tf.cast(slicestep, dtype = tf.complex64)
    lensphase1 = tf.cast(lensphase1, dtype = tf.complex64)
  
    lensphase1 = processor3(lensphase1)
 
    lensphase1 = tf.math.exp(1j * lensphase1)
 
    outxz = []
    # layer1
    slicenum1 = int(z/slicestep)
    for i in range(slicenum1):
        out = prop(ein*lensphase1, slicestep*i, lad, n_sub)
        outxz.append((out[:, int(NN*ssratio/2)]))
    outxz = np.array(outxz)
    outxz = np.transpose(outxz)        
    return outxz

class MyDense(tf.keras.layers.Layer):
    # input: unmodulated field at each wavelength: [NN*ssratio, NN*ssratio]
    # output: modulated field at each wavelength: [NN*ssratio, NN*ssratio]
    # phase & gd: 1D. Need to transfor to 2D
    def __init__(self, inp_dim):
        super(MyDense, self).__init__()
        self.phi = self.add_weight('phi', shape=[inp_dim], initializer=phaseinit1)
        self.gd = self.add_weight('gd', shape=[inp_dim], initializer=gdinit1)
        # self.phi = self.add_weight('phi', shape=[inp_dim], initializer=tf.keras.initializers.HeNormal())
        # self.gd = self.add_weight('gd', shape=[inp_dim], initializer=tf.keras.initializers.HeNormal())
    
    def call(self, inputlist, training=None):   
        # generating the complex field with phase modulation at each wavelength  
        wvll, inputs = inputlist
        phase0 = self.phi
        gd = fmax*tf.sigmoid(self.gd) - fmax/2
        phase0 = (phase0+tf.reverse(phase0, axis = [0]))/2
        gd = (gd+tf.reverse(gd, axis = [0]))/2
        
        phase0 = OneD2TwoD(phase0, TransMatN)   # Convert the 1D to 2D
        gd = OneD2TwoD(gd, TransMatN)
        
        phase0 = tf.cast(phase0, dtype=tf.complex64)
        gd = tf.cast(gd, dtype=tf.complex64)
        phase0 = processor3(phase0)
        gd = processor3(gd)
        phase0 = tf.reshape(phase0, [1, NN*ssratio,NN*ssratio])
        gd = tf.reshape(gd, [1, NN*ssratio, NN*ssratio])
        w = 2*pi*(c/wvll)-w0    # angular frenquency differential     
        phase = phase0 + w*gd
        
        phase = tf.math.exp(1j * phase)
        out0 = inputs*phase
        return [wvll, out0]
    
class MyDense2(tf.keras.layers.Layer):
    # input: unmodulated field at each wavelength: [NN*ssratio, NN*ssratio]
    # output: modulated field at each wavelength: [NN*ssratio, NN*ssratio]
    # phase & gd: 1D. Need to transfor to 2D
    def __init__(self, inp_dim):
        super(MyDense2, self).__init__()
        self.phi2 = self.add_weight('phi2', shape=[inp_dim], initializer=phaseinit2)
        self.gd2 = self.add_weight('gd2', shape=[inp_dim], initializer=gdinit2)
        # self.phi2 = self.add_weight('phi2', shape=[inp_dim], initializer=tf.keras.initializers.HeNormal())
        # self.gd2 = self.add_weight('gd2', shape=[inp_dim], initializer=tf.keras.initializers.HeNormal())        
    
    def call(self, inputlist, training=None):   
        # generating the complex field with phase modulation at each wavelength  
        wvll, inputs = inputlist
        phase0 = self.phi2
        gd = fmax*tf.sigmoid(self.gd2) - fmax/2
        phase0 = (phase0+tf.reverse(phase0, axis = [0]))/2
        gd = (gd+tf.reverse(gd, axis = [0]))/2

        phase0 = OneD2TwoD(phase0, TransMatN)   # Convert the 1D to 2D
        gd = OneD2TwoD(gd, TransMatN)        
        
        phase0 = tf.cast(phase0, dtype=tf.complex64)
        gd = tf.cast(gd, dtype=tf.complex64)
        phase0 = processor3(phase0)
        gd = processor3(gd)
        phase0 = tf.reshape(phase0, [1, NN*ssratio,NN*ssratio])
        gd = tf.reshape(gd, [1, NN*ssratio, NN*ssratio])
        w = 2*pi*(c/wvll)-w0    # angular frenquency differential     
        phase = phase0 + w*gd
        
        phase = tf.math.exp(1j * phase)
        out0 = inputs*phase
        return [wvll, out0]
    
class MyModel(keras.Model):  
    # output: complex field at the output plane at eache wavelength: [NN*ssratio, NN*ssratio]
    def __init__(self):
        super(MyModel, self).__init__()
        self.fc1 = MyDense(N)
        self.fc2 = MyDense2(N)
    def call(self, inputlist, training=None):             
        out = self.fc1(inputlist)     # modulate the phase at 1st plane
        out = prop2(out, gap, n_sub)  # propagating    
        out = self.fc2(out)     # modulate the phase at 2nd plane        
        out = prop2(out, f, n)      # propagating        
        return out[1]

@tf.function()
def mydense(phi, gd, inputs, wvll):
    # input: unmodulated field at each wavelength: [NN*ssratio, NN*ssratio]
    # output: modulated field at each wavelength: [NN*ssratio, NN*ssratio]
    phi = OneD2TwoD(phi, TransMatN)   # Convert the 1D to 2D
    gd = OneD2TwoD(gd, TransMatN)  
        
    phi = tf.cast(phi, dtype = tf.complex64)
    gd = tf.cast(gd, dtype = tf.complex64)
    phase0 = phi
            
    w = 2*pi*(c/wvll)-w0     # angular frenquency differential
    phase = phase0 + w*gd  
    phase = processor3(phase)
    phase = tf.math.exp(1j * tf.cast(phase, dtype=tf.complex64))
    out = inputs*phase
    return out

def mymodel(phi0, phi1, inputs, wvll):   # 功能：输入总的phi和经过preprocess的输入场，给出输出   
    out = mydense(phi0[0], phi0[1], inputs, wvll)    # modulate the phase at the 1st plane
    out_mid = prop(out, gap, wvll, n_sub)        
    out = mydense(phi1[0], phi1[1], out_mid, wvll)    # modulate the phase at the 2nd plane
    out = prop(out, f, wvll, n)
    return out, out_mid

def int_mask(left, right):      # generating a mask for interation
    # span: 2*(rad-1)+1 pixels
    # x = np.linspace(-int(NN*ssratio/2), int(NN*ssratio/2), NN*ssratio)
    # raa = np.square(x)    

    # span: 2*(rad-1)+1 pixels
    # generating a circle at the center
    x = np.linspace(-int(NN*ssratio/2), int(NN*ssratio/2), NN*ssratio)
    y = x
    xx, yy = np.meshgrid(x, y)
    raa = np.square(xx)+np.square(yy)
    
    mask = np.zeros([NN*ssratio, NN*ssratio])
    rad = int((right-left)/2)
    mask[raa < np.square(rad)] = 1
    # move down the circle
    move = int((right+left)/2-NN*ssratio/2)
    a00 = mask[-move:,:]
    a10 = mask[0:-move,:]
    mask = tf.concat([a00, a10], axis = 0)
    return mask

def efficiency(out):
    outi = out
    outi = np.array(outi)
    lin = outi[:, int(NN*ssratio/2)]
    xx = np.linspace(1, NN*ssratio, NN*ssratio)
    spline = UnivariateSpline(xx, lin-np.max(lin)/2, s=0)
    r = spline.roots() # find the roots
    rad = dlp*(r[-1]-r[0])
    left = int(np.floor(2*r[0]-r[-1]))
    right = int(np.ceil(2*r[-1]-r[0]))
    mask = int_mask(left, right)
    effr = np.sum(mask*outi) / np.sum(outi)
    return effr, rad

def StrehlRatio(out, lad):
    # Calculation of the Strehl ratio of the calculated doublet
    # out: calculated output field
    # lad: calculated wavelength
    fp_theo = focuspoint(Ein[0], lad)
    fp_theo_int = np.square(abs(fp_theo))
    out_int = np.square(abs(out))
    out_int = out_int/np.sum(out_int)*np.sum(fp_theo_int)
    sr = np.max(out_int)/np.max(fp_theo_int)
    return sr

@tf.function()
def compute_loss(fp_t, out):
    # compute the loss by complex field
    # loss = tf.reduce_mean(tf.losses.mean_squared_error(fp_t, out))
    
    # compute the loss by intensity
    # fp_t = fp_t*mask
    # out = out*mask    
    # fp_t = tf.cast(fp_t * tf.math.conj(fp_t), dtype=tf.float32)
    fp_t = tf.cast(fp_t, dtype=tf.float32)
    out = tf.cast(out * tf.math.conj(out), dtype=tf.float32)
    
    # normalization
    # fp_t = fp_t/tf.reduce_max(fp_t)
    # out = out/tf.reduce_max(out)
    # out = out*1.2
    
    loss = tf.reduce_mean(tf.losses.mean_squared_error(fp_t, out))
    return loss

@tf.function()
def train_one_step(model, optimizer, inputlist, etar):
    with tf.GradientTape() as tape:
        tape.watch(model.trainable_variables)
        
        out = model(inputlist)
        loss = compute_loss(etar, out)
        
        # compute gradient
        gradss = tape.gradient(loss, model.trainable_variables)

        # update to weights
        # optimizer.apply_gradients(zip(grads, model.trainable_variables))
        # loss and accuracy is scalar tensor
        return loss, gradss

def train(model, optimizer):
    loss = 0.0
    losses2plot = []
    grads0 = []
    grads1 = []
    grads2 = []
    grads3 = []  
    loss = []
    for step1 in range(int(120*rpt/batchsz)-100):
        dataset_batch = next(dataset_iter)
        condition = dataset_batch['condition']
        condition = tf.io.decode_raw(condition, tf.float32)
        condition = tf.cast(condition, dtype = tf.complex64)
        ##
        incidentfield = dataset_batch['incident']
        incidentfield = tf.io.decode_raw(incidentfield, tf.complex64)
        incidentfield = tf.reshape(incidentfield, [-1, NN*ssratio, NN*ssratio])
        incidentfield = tf.cast(incidentfield, dtype = tf.complex64)
        ##
        inttar = dataset_batch['patt']
        inttar = tf.io.decode_raw(inttar, tf.float32)
        inttar = tf.reshape(inttar, [-1, NN*ssratio, NN*ssratio])
        inttar = tf.cast(inttar, dtype = tf.float32)
        ##
        wvll = condition[:,0]
        wvll = tf.reshape(wvll, [batchsz, 1,1])
        inputlist = [wvll, incidentfield]
        losstmp, gradstmp = train_one_step(model, optimizer, inputlist, inttar)
        loss.append(losstmp)
        grads0.append(gradstmp[0])
        grads1.append(gradstmp[1])        
        grads2.append(gradstmp[2])
        grads3.append(gradstmp[3])        
        
        if (step1 % batchratio == 0) & (step1 >0):
            loss_ba = tf.reduce_mean(loss)
            
            grads_ba0 = tf.reduce_mean(grads0, axis = 0)
            grads_ba1 = tf.reduce_mean(grads1, axis = 0) 
            grads_ba2 = tf.reduce_mean(grads2, axis = 0)
            grads_ba3 = tf.reduce_mean(grads3, axis = 0)             

            grads_ba = []
            grads_ba.append(grads_ba0)
            grads_ba.append(grads_ba1)            
            grads_ba.append(grads_ba2)
            grads_ba.append(grads_ba3)            
            
            optimizer.apply_gradients(zip(grads_ba, model.trainable_variables))
            losses2plot.append(loss_ba)
            phi = model.trainable_variables

            result0 = []
            result1 = []
            result0.append(np.array((phi[0]+tf.reverse(phi[0],axis=[0]))/2))
            result0.append(np.array((phi[1]+tf.reverse(phi[1],axis=[0]))/2))
            result0[1] = fmax*tf.sigmoid(result0[1])-fmax/2
            result1.append(np.array((phi[2]+tf.reverse(phi[2],axis=[0]))/2))
            result1.append(np.array((phi[3]+tf.reverse(phi[3],axis=[0]))/2))
            result1[1] = fmax*tf.sigmoid(result1[1])-fmax/2
            print('RMSE: ', loss_ba.numpy(), '. Step: ', step1)
            np.save('AML-byint-v5.5-NA0.3-p0.28-gap335-r80-cont-focusinair--1-1fs-1DOptimizedIniVal-meta0.npy', result0)
            np.save('AML-byint-v5.5-NA0.3-p0.28-gap335-r80-cont-focusinair--1-1fs-1DOptimizedIniVal-meta1.npy', result1)
            # np.save('GradientTmp.npy', np.array(grads_ba))
            grads0 = []
            grads1 = []
            grads2 = []
            grads3 = []
            loss = []
    return losses2plot

def main():
    model = MyModel()
    optimizer = optimizers.Adam()

    losses2plot = train(model, optimizer)

    x1 = [i for i in range(len(losses2plot))]
    plt.figure()
    plt.plot(x1, losses2plot, color='C0')
    plt.ylabel('MSE')
    plt.xlabel('Step')
    plt.legend()
    plt.show()
    return losses2plot

if __name__ == '__main__':
    losses = main()
    
    
    